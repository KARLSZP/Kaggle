{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Import packages and load preprocessed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import pickle as pk\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from utilities import clean_posts, postVectorizer\n",
    "from RF import RandomForest, cross_validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier,plot_importance\n",
    "\n",
    "method_dict = {\n",
    "    'RF': 'RandomForest',\n",
    "    'SVM': 'SVM',\n",
    "    'XGB': 'XGBoost',\n",
    "    'DL': 'DeepLearning'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./tfidf_df.pk', 'rb') as pkl:\n",
    "    tfidf_df = pk.load(pkl)\n",
    "\n",
    "with open('./df.pk', 'rb') as pkl:\n",
    "    df = pk.load(pkl)\n",
    "    \n",
    "# with open('./tfidf_df_IE.pk', 'rb') as pkl:\n",
    "#     tfidf_df_IE = pk.load(pkl)\n",
    "\n",
    "# with open('./tfidf_df_NS.pk', 'rb') as pkl:\n",
    "#     tfidf_df_NS = pk.load(pkl)\n",
    "\n",
    "# with open('./tfidf_df_TF.pk', 'rb') as pkl:\n",
    "#     tfidf_df_TF = pk.load(pkl)\n",
    "\n",
    "# with open('./tfidf_df_JP.pk', 'rb') as pkl:\n",
    "#     tfidf_df_JP = pk.load(pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Training and Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_by_type\n",
    "# @params:\n",
    "#   _type: (string), type to be classified; types:[IE, NS, TF, JP]\n",
    "#  method: (string), type of the classifier; methods:['RF', 'SVM', 'XGB']\n",
    "##\n",
    "\n",
    "def train_by_type(_type, method='RF', benchmark=False):\n",
    "    y = df[_type].values.reshape(-1, 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(tfidf_df.values, y, test_size=0.33, train_size=0.67,\n",
    "                                                        random_state=13, shuffle=True, stratify=y)\n",
    "    \n",
    "    print(\"# @Training START #\")\n",
    "    if method == 'RF':\n",
    "#         print(X_train.shape, y_train.reshape(-1,1).shape)\n",
    "        clf = RandomForest(n_estimators=100, verbose=0, min_leaf_size=3)\n",
    "        clf.fit(np.concatenate((X_train, y_train), axis=1))\n",
    "    \n",
    "    elif method == 'SVM':\n",
    "        clf = SVC(gamma='auto', probability=True)\n",
    "        clf.fit(X_train, y_train)\n",
    "    \n",
    "    elif method == 'XGB':\n",
    "        clf = XGBClassifier()\n",
    "        clf.fit(X_train, y_train, \n",
    "                early_stopping_rounds=10,\n",
    "                eval_metric=\"logloss\",\n",
    "                eval_set=[(X_test, y_test)],\n",
    "                verbose=False)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid Method.\")\n",
    "        \n",
    "    print(\"# @Training END #\\n\")\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    if benchmark:\n",
    "        print(\"# @Scoring START # --- {:s}\".format(method_dict[method]))\n",
    "        time.sleep(0.5)\n",
    "        print(\"Type: {}: {} : {} = {} : {}\".format(_type, _type[0], _type[1], sum(y)/len(y),1-sum(y)/len(y)))\n",
    "        time.sleep(0.5)\n",
    "        pred_train = [clf.predict(i.reshape(1,-1)) for i in tqdm(X_train)]\n",
    "        print(\"Accuracy on training set - %s\" % _type, accuracy_score(y_train, pred_train))\n",
    "        print(\"F1 Score on training set - %s\" % _type, (if set(pred_train) f1_score(y_train, pred_train))\n",
    "        time.sleep(0.5)\n",
    "        pred_test = [clf.predict(i.reshape(1,-1)) for i in tqdm(X_test)]\n",
    "        print(\"Accuracy on testing set - %s\" % _type, accuracy_score(y_test, pred_test))\n",
    "        print(\"F1 Score on testing set - %s\" % _type, f1_score(y_test, pred_test))\n",
    "        print(\"# @Scoring END #\\n\")\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# @Training START #\n",
      "# @Training END #\n",
      "\n",
      "# @Scoring START # --- RandomForest\n",
      "Type: IE: I : E = [0.23043228]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5812/5812 [00:27<00:00, 208.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set - IE 0.9970750172057812\n",
      "F1 Score on training set - IE 0.9936114242765878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2863/2863 [00:13<00:00, 209.52it/s]\n",
      "/home/karl/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing set - IE 0.7694725812085226\n",
      "F1 Score on testing set - IE 0.0\n",
      "# @Scoring END #\n",
      "\n",
      "# @Training START #\n",
      "# @Training END #\n",
      "\n",
      "# @Scoring START # --- RandomForest\n",
      "Type: NS: N : S = [0.13798271]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5812/5812 [00:28<00:00, 202.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set - NS 0.9805574673090158\n",
      "F1 Score on training set - NS 0.9242119382964453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2863/2863 [00:13<00:00, 209.13it/s]\n",
      "/home/karl/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing set - NS 0.8620328326929794\n",
      "F1 Score on testing set - NS 0.0\n",
      "# @Scoring END #\n",
      "\n",
      "# @Training START #\n",
      "# @Training END #\n",
      "\n",
      "# @Scoring START # --- RandomForest\n",
      "Type: TF: T : F = [0.4589049]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5812/5812 [00:27<00:00, 208.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set - TF 0.9998279421885754\n",
      "F1 Score on training set - TF 0.9998125585754452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2863/2863 [00:13<00:00, 209.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing set - TF 0.7027593433461404\n",
      "F1 Score on testing set - TF 0.625604927408711\n",
      "# @Scoring END #\n",
      "\n",
      "# @Training START #\n",
      "# @Training END #\n",
      "\n",
      "# @Scoring START # --- RandomForest\n",
      "Type: JP: J : P = [0.39585014]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5812/5812 [00:27<00:00, 208.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set - JP 0.9994838265657261\n",
      "F1 Score on training set - JP 0.9993476842791911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2863/2863 [00:13<00:00, 208.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing set - JP 0.6234718826405868\n",
      "F1 Score on testing set - JP 0.1820940819423369\n",
      "# @Scoring END #\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clf_ie = train_by_type('IE', 'RF', benchmark=True)\n",
    "clf_ns = train_by_type('NS', 'RF', benchmark=True)\n",
    "clf_tf = train_by_type('TF', 'RF', benchmark=True)\n",
    "clf_jp = train_by_type('JP', 'RF', benchmark=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_posts = \"./testdata/ForumMessages.csv\"\n",
    "kdf = pd.read_csv(kaggle_posts)\n",
    "kdf = kdf.drop(columns=[\"ForumTopicId\", \"Id\", \"PostDate\", \"ReplyToForumMessageId\", \"Medal\", \"MedalAwardDate\"])\n",
    "kdf = kdf.dropna()\n",
    "kdf.Message = kdf.Message.apply(lambda x:np.NaN if len(x)<200 else x)\n",
    "kdf = kdf.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pi followed your link and i didnt findnbspa href which can take in sparse matrices and is probably best suited to large datasets like ours it works just like any other classifierp pcodeclf sgdclassifier clffitx y etcetccodenbspp pas for your error what is typextrain and typeytrain QST i think sklearn only supports csrmode sparse matricesp'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_posts(kdf.values[32932][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
