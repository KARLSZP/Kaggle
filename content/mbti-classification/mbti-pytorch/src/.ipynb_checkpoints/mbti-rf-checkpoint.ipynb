{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/tfidf_df.pk', 'rb') as pkl:\n",
    "    tfidf_df = pk.load(pkl)\n",
    "\n",
    "with open('pickles/df.pk', 'rb') as pkl:\n",
    "    df = pk.load(pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/tfidf_df_IE.pk', 'rb') as pkl:\n",
    "        dataset = pk.load(pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(dataset, para_dict):\n",
    "    _n_estimators = []\n",
    "    _max_depth = []\n",
    "    _min_leaf_size = []\n",
    "    if \"n_estimators\" in para_dict.keys():\n",
    "        _n_estimators = para_dict[\"n_estimators\"]\n",
    "    if \"max_depth\" in para_dict.keys():\n",
    "        _max_depth = para_dict[\"max_depth\"]\n",
    "    if \"min_leaf_size\" in para_dict.keys():\n",
    "        _min_leaf_size = para_dict[\"min_leaf_size\"]\n",
    "    for i in _n_estimators if len(_n_estimators) else [None]:\n",
    "        for j in _max_depth if len(_max_depth) else [None]:\n",
    "            for k in _min_leaf_size if len(_min_leaf_size) else [None]:\n",
    "                print(i,j,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 None 2\n",
      "10 None 5\n",
      "10 5 2\n",
      "10 5 5\n",
      "10 10 2\n",
      "10 10 5\n",
      "20 None 2\n",
      "20 None 5\n",
      "20 5 2\n",
      "20 5 5\n",
      "20 10 2\n",
      "20 10 5\n"
     ]
    }
   ],
   "source": [
    "cross_validation([], {\"n_estimators\":[10,20], \"max_depth\":[None, 5, 10], \"min_leaf_size\":[2, 5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy of:0.4 in -1s, with params:\n",
      "  n_estimators:1\n",
      "  max_depth:None\n",
      "  min_leaf_size:2\n"
     ]
    }
   ],
   "source": [
    "# train_by_type\n",
    "# @params:\n",
    "#   _type: (string), type to be classified; types:[IE, NS, TF, JP]\n",
    "#  method: (string), type of the classifier; methods:['RF', 'SVM', 'XGB']\n",
    "##\n",
    "\n",
    "def train_by_type(_type, method='RF'):\n",
    "    y = df[_type].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(tfidf_df, y, test_size=0.33, train_size=0.67,\n",
    "                                                        random_state=13, shuffle=True, stratify=y)\n",
    "    \n",
    "    print(\"# @Training START #\")\n",
    "    if method == 'RF':\n",
    "#         print(X_train.shape, y_train.reshape(-1,1).shape)\n",
    "        clf = RandomForest(n_estimators=100)\n",
    "        clf.fit(np.concatenate((X_train, y_train.reshape(-1,1)), axis=1))\n",
    "    \n",
    "    elif method == 'SVM':\n",
    "        clf = SVC(gamma='auto', probability=True)\n",
    "        clf.fit(X_train, y_train)\n",
    "    \n",
    "    elif method == 'XGB':\n",
    "        clf = XGBClassifier()\n",
    "        clf.fit(X_train, y_train, \n",
    "                early_stopping_rounds=10,\n",
    "                eval_metric=\"logloss\",\n",
    "                eval_set=[(X_test, y_test)],\n",
    "                verbose=False)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid Method.\")\n",
    "        \n",
    "    print(\"# @Training END #\\n\")\n",
    "    \n",
    "    method_dict = {\n",
    "        'RF': 'RandomForest',\n",
    "        'SVM': 'SVM',\n",
    "        'XGB': 'XGBoost',\n",
    "        'DL': 'DeepLearning'\n",
    "    }\n",
    "    print(\"# @Scoring START # --- {:s}\".format(method_dict[method]))\n",
    "    print(\"Type: %s:\" % _type, sum(y)/len(y))\n",
    "    print(\"Accuracy %s\" % _type, accuracy_score(y_test, clf.predict(X_test)))\n",
    "#     print(\"AUC %s\" % _type, roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]))\n",
    "    print(\"# @Scoring END #\\n\")\n",
    "    \n",
    "    return clf\n",
    "\n",
    "train_by_type('JP', 'RF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
