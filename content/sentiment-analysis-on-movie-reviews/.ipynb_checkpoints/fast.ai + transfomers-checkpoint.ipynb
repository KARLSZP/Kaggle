{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Movie Reviews\n",
    "\n",
    "### Classify the sentiment of sentences from the Rotten Tomatoes dataset\n",
    "\n",
    "\n",
    "The dataset is comprised of tab-separated files with phrases from the Rotten Tomatoes dataset. The train/test split has been preserved for the purposes of benchmarking, but the sentences have been shuffled from their original order. Each Sentence has been parsed into many phrases by the Stanford parser. Each phrase has a PhraseId. Each sentence has a SentenceId. Phrases that are repeated (such as short/common words) are only included once in the data.\n",
    "\n",
    "train.tsv contains the phrases and their associated sentiment labels. We have additionally provided a SentenceId so that you can track which phrases belong to a single sentence.\n",
    "test.tsv contains just phrases. You must assign a sentiment label to each phrase.\n",
    "The sentiment labels are:\n",
    "\n",
    "0 - negative\\\n",
    "1 - somewhat negative\\\n",
    "2 - neutral\\\n",
    "3 - somewhat positive\\\n",
    "4 - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from transformers import AlbertModel, AlbertPreTrainedModel, AlbertTokenizer\n",
    "\n",
    "train_data_path = Path(\"./dataset/train.tsv\")\n",
    "test_data_path = Path(\"./dataset/test.tsv\")\n",
    "\n",
    "OUTPUT_SIZE = 5\n",
    "EPOCHS = 100\n",
    "TRAIN_RATE = 0.9\n",
    "BATCH_SIZE = 64\n",
    "ACCUMULATE_STRIDE = 3\n",
    "LR = 1e-5\n",
    "WARMUP_RATE = 0.1\n",
    "\n",
    "MAX_SEQ_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(train_data_path)\n",
    "TRAIN_SIZE = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 283 artists>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lens = [len(i) for i in df.Phrase.values]\n",
    "counter = [lens.count(i) for i in range(max(lens))]\n",
    "\n",
    "plt.bar(x=range(max(lens)), height=counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class reviewDataset(Dataset):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        super(reviewDataset, self).__init__()\n",
    "        self._data = data\n",
    "        self._size = len(data)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self._data[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._size\n",
    "\n",
    "    def __iter__(self):\n",
    "        for x in self._data:\n",
    "            yield x\n",
    "\n",
    "    def get_labels(self):\n",
    "        return set(data[[1]])\n",
    "    \n",
    "\n",
    "def collate_fn(batch):\n",
    "    inputs = [i[0] for i in batch]\n",
    "    tokens = tokenizer.encode_plus(inputs,\n",
    "                                   max_length=MAX_SEQ_LEN,\n",
    "                                   pad_to_max_length=True,\n",
    "                                   return_tensors='pt')\n",
    "    print(tokens)\n",
    "    return tokens[0], tokens[1], tokens[2], batch[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = reviewDataset(df[[\"Phrase\", \"Sentiment\"]].values)\n",
    "data = DataLoader(dataset, \n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  shuffle=True,\n",
    "                  collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-714e46224123>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-61-5b51de651e55>\u001b[0m in \u001b[0;36mcollate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     27\u001b[0m                                    \u001b[0mpad_to_max_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                                    return_tensors='pt')\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'shape'"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(data):\n",
    "    if i>2:\n",
    "        break\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlbertPreTrainedModel.from_pretrained('albert-base-v2')\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-large-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class albertForSentimentAnalysis(AlbertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(albertForSentimentAnalysis, self).__init__(config)\n",
    "        self.albert = AlbertModel(config)\n",
    "        self.outputs = nn.Linear(config.hidden_size, OUTPUT_SIZE)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, input_ids,\n",
    "                attention_mask=None, token_type_ids=None, \n",
    "                position_ids=None, head_mask=None):\n",
    "        \n",
    "        cls = self.albert(input_ids=input_ids,\n",
    "                          attention_mask=attention_mask,\n",
    "                          token_type_ids=token_type_ids,\n",
    "                          position_ids=position_ids,\n",
    "                          head_mask=head_mask)\n",
    "        \n",
    "        cls = self.outputs(cls)\n",
    "        \n",
    "        return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.to(device)\n",
    "\n",
    "params_to_tune = list(model.named_parameters())\n",
    "params_no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "\n",
    "params_with_weight = [\n",
    "    {'params': [p for n, p in params_to_tune if not any(i in n for i in params_no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in params_to_tune if any(i in n for i in params_no_decay)], 'weight_decay': 0.0}]\n",
    "\n",
    "\n",
    "num_training_steps = int(EPOCHS * TRAIN_SIZE / BATCH_SIZE / ACCUMULATE_STRIDE)\n",
    "num_warmup_steps = int(num_training_steps * WARMUP_RATE)\n",
    "\n",
    "# training tools\n",
    "model = albertForSentimentAnalysis.from_pretrained('albert-base-v2')\n",
    "optimizer = AdamW(params=params_with_weight, lr=LR, correct_bias=False)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer=optimizer, \n",
    "                                            num_warmup_steps=num_warmup_steps,\n",
    "                                            num_training_steps=num_training_steps)\n",
    "\n",
    "# Activate training mode\n",
    "model.zero_grad()\n",
    "model = model.train()\n",
    "\n",
    "# Prepare data\n",
    "train_data = QADataset(pt_dict)\n",
    "sub_train_,\n",
    "sub_test_ = random_split(train_data, \n",
    "                         [TRAIN_SIZE, \n",
    "                          train_data.size - TRAIN_SIZE])\n",
    "train_loader = DataLoader(sub_train_,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
